# Basic broker and listener configuration
broker.id=0
listeners=SASL_PLAINTEXT://kafka.kerberos-demo.local:9093
zookeeper.connect=zookeeper.kerberos-demo.local:2181
log.dirs=/var/lib/kafka

offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
num.partitions=12


# Kerberos / GSSAPI Authentication mechanism
sasl.enabled.mechanisms=GSSAPI
sasl.kerberos.service.name=kafka


# Configure replication to require Kerberos:
sasl.mechanism.inter.broker.protocol=GSSAPI
security.inter.broker.protocol=SASL_PLAINTEXT


# Authorization config:
authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
zookeeper.set.acl=true
allow.everyone.if.no.acl.found=false
super.users=User:admin;User:kafka


# Demonstrate setting up the Confluent Metrics Reporter with required *client* credentials
metric.reporters=io.confluent.metrics.reporter.ConfluentMetricsReporter
confluent.metrics.reporter.bootstrap.servers=kafka:9093
confluent.metrics.reporter.sasl.mechanism=GSSAPI
confluent.metrics.reporter.security.protocol=SASL_PLAINTEXT
confluent.metrics.reporter.sasl.kerberos.service.name=kafka
confluent.metrics.reporter.sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required \
   useKeyTab=true \
   storeKey=true \
   keyTab="/var/lib/secret/kafka-admin.key" \
   principal="admin/for-kafka@TEST.CONFLUENT.IO";

confluent.metrics.reporter.topic.replicas=1
confluent.support.metrics.enable=false
confluent.support.customer.id=anonymous
